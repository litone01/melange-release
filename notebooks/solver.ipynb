{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ILP Solver Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "# Convert max throughput profiling to a mapping from request size to load\n",
    "def tputs_to_loads_2d(max_tputs: List[List[float]]):\n",
    "    loads = []\n",
    "    for i in range(len(max_tputs)):\n",
    "        loads.append([])\n",
    "        for j in range(len(max_tputs[0])):\n",
    "            load = 1 / max_tputs[i][j]\n",
    "            loads[-1].append(load)\n",
    "    return loads\n",
    "\n",
    "def display_experiment_results(results, solver_labels, ilp_result):\n",
    "  df = pd.DataFrame(results)\n",
    "  df.fillna(0, inplace=True)\n",
    "\n",
    "  # Add the last column filled with zeros\n",
    "  df['Savings'] = [str(round(((x[\"cost\"] - ilp_result[\"cost\"])/x[\"cost\"]) * 100, 2)) + \"%\" for x in results]\n",
    "\n",
    "  # Ensure the 'cost' column is second to last and 'LastColumn' is last, this step might need adjustment based on actual GPU types\n",
    "  # Assuming we don't know all GPU types in advance, let's dynamically sort columns except for 'cost' and 'LastColumn'\n",
    "  gpu_columns = [col for col in df.columns if col not in ['cost', 'Savings']]\n",
    "  sorted_columns = gpu_columns + ['cost', 'Savings']\n",
    "  df = df[sorted_columns]\n",
    "  df.index = solver_labels\n",
    "\n",
    "  # Display the table\n",
    "  print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ILP Solver for Heterogeneous Accelerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pulp\n",
    "from pulp import LpVariable, LpProblem, LpMinimize, LpInteger\n",
    "\n",
    "def run_ILP_solver(workload_distribution, overall_rate, slice_factor, gpu_info, logs=False):\n",
    "    # Multiply overall rate across distribution.\n",
    "    request_rate_histogram = []\n",
    "    for i in range(len(workload_distribution)):\n",
    "        request_rate_histogram.append([])\n",
    "        for j in range(len(workload_distribution[0])):\n",
    "            request_rate_histogram[-1].append(workload_distribution[i][j] * overall_rate)\n",
    "\n",
    "    # Convert the profiled max throughputs into mapping from request size to load\n",
    "    for gpu in gpu_info:\n",
    "        gpu_info[gpu][\"loads\"] = tputs_to_loads_2d(gpu_info[gpu][\"tputs\"])\n",
    "\n",
    "    gpu_types = list(gpu_info.keys())\n",
    "    cost_vector = [gpu_info[gpu][\"cost\"] for gpu in gpu_types]\n",
    "\n",
    "    # Create slices, which is a single dimension.\n",
    "    slices = []\n",
    "    for i in range(len(request_rate_histogram)):\n",
    "      for j in range(len(request_rate_histogram[i])):\n",
    "        for _ in range(slice_factor):\n",
    "            slices.append(request_rate_histogram[i][j] / slice_factor)\n",
    "\n",
    "    # Create slice-to-load mapping, which is a single dimension.\n",
    "    for gpu in gpu_types:\n",
    "        slice_loads = []\n",
    "        for i in range(len(gpu_info[gpu][\"loads\"])):\n",
    "            for j in range(len(gpu_info[gpu][\"loads\"][i])):\n",
    "                for _ in range(slice_factor):\n",
    "                    slice_loads.append(gpu_info[gpu][\"loads\"][i][j])\n",
    "        assert len(slices) == len(slice_loads)\n",
    "        gpu_info[gpu][\"slice_loads\"] = slice_loads\n",
    "\n",
    "\n",
    "    # Decision matrix value is binary. The slice is assigned to a GPU, or it isn't.\n",
    "    matrix_rows = len(slices)\n",
    "    matrix_cols = len(gpu_types)\n",
    "\n",
    "    # Vector value is non-negative integer of how many of each GPU type are needed\n",
    "    vector_length = matrix_cols\n",
    "\n",
    "    decision_matrix = [[LpVariable(f\"x_{i}_{j}\", cat=LpInteger, lowBound=0, upBound=1) for j in range(matrix_cols)] for i in range(matrix_rows)]\n",
    "    decision_vector = [LpVariable(f\"y_{i}\", cat=LpInteger, lowBound=0) for i in range(vector_length)]\n",
    "\n",
    "    # Objective: minimize cost\n",
    "    problem = LpProblem(\"GpuAllocation\", LpMinimize)\n",
    "    problem += pulp.lpSum([decision_vector[i] * cost_vector[i] for i in range(len(decision_vector))])\n",
    "\n",
    "    # C1: Each row of decision matrix must sum to exactly 1 (ie, each slice assigned to one GPU)\n",
    "    for i in range(len(decision_matrix)):\n",
    "        problem += pulp.lpSum(decision_matrix[i]) == 1\n",
    "\n",
    "    # C2: Load of column of decision matrix must fit in decision vector capacity\n",
    "    for j in range(len(decision_matrix[0])):\n",
    "        # j is idx of GPU type, i is slice\n",
    "        problem += pulp.lpSum([decision_matrix[i][j] * gpu_info[gpu_types[j]][\"slice_loads\"][i] * slices[i] for i in range(len(decision_matrix))]) <= decision_vector[j]\n",
    "\n",
    "    # Solve the problem\n",
    "    problem.solve(pulp.PULP_CBC_CMD(msg=0))\n",
    "\n",
    "    # Print the results\n",
    "    if logs:\n",
    "        print(f'Decision Matrix:')\n",
    "        for row in decision_matrix:\n",
    "            print([var.value() for var in row])\n",
    "        print(f'Decision Vector:')\n",
    "        print(f'{[var.value() for var in decision_vector]}')\n",
    "\n",
    "    if pulp.LpStatus[problem.status] != 'Optimal':\n",
    "        return None\n",
    "\n",
    "    solution_dict = {}\n",
    "    for i in range(len(decision_vector)):\n",
    "        solution_dict[gpu_types[i]] = decision_vector[i].value()\n",
    "\n",
    "    total_cost = 0\n",
    "    for gpu in solution_dict:\n",
    "        total_cost += solution_dict[gpu] * gpu_info[gpu][\"cost\"]\n",
    "    solution_dict[\"cost\"] = total_cost\n",
    "\n",
    "    return solution_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Solver\n",
    "Choose the parameters of the experiment setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A10G': 10.0, 'A100': 0.0, 'cost': 10.1}\n"
     ]
    }
   ],
   "source": [
    "# Example inputs, replace them with your own data\n",
    "gpu_info_example = {\n",
    "   \"A10G\" : {\n",
    "      \"cost\": 1.01,\n",
    "      \"tputs\": [[5, 1],\n",
    "                [10,5]],\n",
    "   },\n",
    "   \"A100\" : {\n",
    "      \"cost\": 3.67,\n",
    "      \"tputs\": [[20, 2],\n",
    "                [50, 20]],\n",
    "   }\n",
    "}\n",
    "workload_distribution = [[0.25, 0.5],\n",
    "                         [0.25, 0.25]]\n",
    "overall_rate = 16\n",
    "slice_factor = 1\n",
    "\n",
    "# Run the ILP solver\n",
    "print(run_ILP_solver(workload_distribution=workload_distribution, overall_rate=overall_rate, slice_factor=slice_factor, gpu_info=gpu_info_example, logs=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
