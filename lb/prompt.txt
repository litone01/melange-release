curl -L http://3.137.200.198:8000/v1/completions \
    -X POST \
    -d '{"model": "meta-llama/Llama-2-7b-hf", "prompt": "Hello, world", "max_tokens": 100}' \
    -H 'Content-Type: application/json'

curl -L http://34.28.94.90:8000/v1/completions \
    -X POST \
    -d '{"model": "meta-llama/Llama-2-7b-hf", "prompt": "Hello, world", "max_tokens": 100}' \
    -H 'Content-Type: application/json'

curl -L http://0.0.0.0:8000/v1/completions \
    -X POST \
    -d '{"model": "meta-llama/Llama-2-7b-hf", "prompt": "Hello, world", "max_tokens": 100}' \
    -H 'Content-Type: application/json'


curl http://34.173.38.88:8000/v1/completions \
    -X POST \
    -d '{"model": "meta-llama/Llama-2-7b-hf", "prompt": "Hello, world"}' \
    -H 'Content-Type: application/json'


curl -L http://0.0.0.0:8000/v1/chat/completions \
    -X POST \
    -d '{"model": "mistralai/Mixtral-8x7B-Instruct-v0.1", "prompt": "hello world"}' \
    -H 'Content-Type: application/json'


curl -L http://0.0.0.0:8000/forward \
    -X POST \
    -d '{"model": "meta-llama/Llama-2-7b-hf", "prompt": "Hello, world", "max_tokens": 100}' \
    -H 'Content-Type: application/json'

curl -L http://0.0.0.0:8000/forward \
    -X POST \
    -d '{"prompt": "hello world"}' \
    -H 'Content-Type: application/json'

curl -L http://0.0.0.0:8001/receive \
-X POST \
-d '{"model": "mistralai/Mixtral-8x7B-Instruct-v0.1", "prompt": "hello world"}' \
-H 'Content-Type: application/json'
